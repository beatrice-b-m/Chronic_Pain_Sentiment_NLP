{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb10805-7026-4ee5-bcf1-5b0376dc4ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrow51/.conda/envs/transformers/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7676cc0250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch\n",
    "# import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import Accuracy, AUROC, F1Score, Precision, Recall\n",
    "from itertools import chain\n",
    "\n",
    "# seed torch operations\n",
    "SEED = 13\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b345eeb-df80-40bc-8130-4c64030441be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device...\n"
     ]
    }
   ],
   "source": [
    "# get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"using {device} device...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74155e41-6a0e-45fb-a0ca-c99b89e70a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/localdata/Data/bea/nlp/bmi550/project/chronic_pain_model_data/dev.csv',\n",
       " '/opt/localdata/Data/bea/nlp/bmi550/project/chronic_pain_model_data/test.csv',\n",
       " '/opt/localdata/Data/bea/nlp/bmi550/project/chronic_pain_model_data/train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(\"/opt/localdata/Data/bea/nlp/bmi550/project/chronic_pain_model_data/*.csv\")\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c7bb5d-b325-42a7-a087-c927d486c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1365360731055673345</td>\n",
       "      <td>new publication. chronic pain assessment is un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1365571852245078018</td>\n",
       "      <td>today is a bad day for me. chronic pain is a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1365710497903960066</td>\n",
       "      <td>&lt;hashtag&gt;  call for submissions\\n\\nif you’re a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1365783013674606598</td>\n",
       "      <td>chronic pain does not &lt;allcaps&gt; have to contro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1366344621786341381</td>\n",
       "      <td>call for participants for &lt;user&gt; phd research:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>2105</td>\n",
       "      <td>1478736266682408961</td>\n",
       "      <td>chronic pain and the self pity, depression tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>2106</td>\n",
       "      <td>1478743181357469697</td>\n",
       "      <td>pinpointing pain is not always easy as our bod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>2107</td>\n",
       "      <td>1478787131451625477</td>\n",
       "      <td>“it is just amazing how chronic pain can paral...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>2108</td>\n",
       "      <td>1478801225399238656</td>\n",
       "      <td>anyone i know with autoimmune / chronic pain i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>2109</td>\n",
       "      <td>1478826190358163460</td>\n",
       "      <td>ad &lt;allcaps&gt;-affiliate  /  /  i genuinely cann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             tweet_id  \\\n",
       "0         0  1365360731055673345   \n",
       "1         1  1365571852245078018   \n",
       "2         2  1365710497903960066   \n",
       "3         3  1365783013674606598   \n",
       "4         4  1366344621786341381   \n",
       "...     ...                  ...   \n",
       "3294   2105  1478736266682408961   \n",
       "3295   2106  1478743181357469697   \n",
       "3296   2107  1478787131451625477   \n",
       "3297   2108  1478801225399238656   \n",
       "3298   2109  1478826190358163460   \n",
       "\n",
       "                                                   text  label  \n",
       "0     new publication. chronic pain assessment is un...      0  \n",
       "1     today is a bad day for me. chronic pain is a b...      1  \n",
       "2     <hashtag>  call for submissions\\n\\nif you’re a...      0  \n",
       "3     chronic pain does not <allcaps> have to contro...      0  \n",
       "4     call for participants for <user> phd research:...      0  \n",
       "...                                                 ...    ...  \n",
       "3294  chronic pain and the self pity, depression tra...      0  \n",
       "3295  pinpointing pain is not always easy as our bod...      0  \n",
       "3296  “it is just amazing how chronic pain can paral...      0  \n",
       "3297  anyone i know with autoimmune / chronic pain i...      1  \n",
       "3298  ad <allcaps>-affiliate  /  /  i genuinely cann...      0  \n",
       "\n",
       "[3299 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [pd.read_csv(f) for f in file_list]\n",
    "df = pd.concat(df_list, axis=0).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d04c553-a7f3-4bfd-8e6d-5e8a7c1a8451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1365360731055673345</td>\n",
       "      <td>new publication. chronic pain assessment is un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1365571852245078018</td>\n",
       "      <td>today is a bad day for me. chronic pain is a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1365710497903960066</td>\n",
       "      <td>&lt;hashtag&gt;  call for submissions\\n\\nif you’re a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1365783013674606598</td>\n",
       "      <td>chronic pain does not &lt;allcaps&gt; have to contro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1366344621786341381</td>\n",
       "      <td>call for participants for &lt;user&gt; phd research:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>2105</td>\n",
       "      <td>1478736266682408961</td>\n",
       "      <td>chronic pain and the self pity, depression tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>2106</td>\n",
       "      <td>1478743181357469697</td>\n",
       "      <td>pinpointing pain is not always easy as our bod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>2107</td>\n",
       "      <td>1478787131451625477</td>\n",
       "      <td>“it is just amazing how chronic pain can paral...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>2108</td>\n",
       "      <td>1478801225399238656</td>\n",
       "      <td>anyone i know with autoimmune / chronic pain i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>2109</td>\n",
       "      <td>1478826190358163460</td>\n",
       "      <td>ad &lt;allcaps&gt;-affiliate  /  /  i genuinely cann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             tweet_id  \\\n",
       "0         0  1365360731055673345   \n",
       "1         1  1365571852245078018   \n",
       "2         2  1365710497903960066   \n",
       "3         3  1365783013674606598   \n",
       "4         4  1366344621786341381   \n",
       "...     ...                  ...   \n",
       "3294   2105  1478736266682408961   \n",
       "3295   2106  1478743181357469697   \n",
       "3296   2107  1478787131451625477   \n",
       "3297   2108  1478801225399238656   \n",
       "3298   2109  1478826190358163460   \n",
       "\n",
       "                                                   text  label  \n",
       "0     new publication. chronic pain assessment is un...      0  \n",
       "1     today is a bad day for me. chronic pain is a b...      1  \n",
       "2     <hashtag>  call for submissions\\n\\nif you’re a...      0  \n",
       "3     chronic pain does not <allcaps> have to contro...      0  \n",
       "4     call for participants for <user> phd research:...      0  \n",
       "...                                                 ...    ...  \n",
       "3294  chronic pain and the self pity, depression tra...      0  \n",
       "3295  pinpointing pain is not always easy as our bod...      0  \n",
       "3296  “it is just amazing how chronic pain can paral...      0  \n",
       "3297  anyone i know with autoimmune / chronic pain i...      1  \n",
       "3298  ad <allcaps>-affiliate  /  /  i genuinely cann...      0  \n",
       "\n",
       "[3299 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121d4fa4-23b0-40c2-82e8-b3f044564e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2765\n",
       "1     534\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3948d327-6e7b-4b6a-987c-8c6db7df9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FrameParams:\n",
    "    df: pd.DataFrame\n",
    "    class_name: str\n",
    "    class_val: float\n",
    "\n",
    "\n",
    "# function to get the set of unique patient ids in the dataframe\n",
    "# then split based on the train/val/test proportion\n",
    "def split_ids(id_col, test_prop, validation, seed):\n",
    "    # get set of unique ids and convert to a list\n",
    "    id_list = list(set(id_col))\n",
    "\n",
    "    # shuffle id list\n",
    "    random.Random(seed).shuffle(id_list)\n",
    "\n",
    "    # get split lengths\n",
    "    id_list_len = len(id_list)\n",
    "\n",
    "    # get the length of indexes to add to the train/test sets\n",
    "    train_prop = 1.0 - (2 * test_prop)\n",
    "    train_len = int(train_prop * id_list_len)\n",
    "    test_len = int(test_prop * id_list_len)\n",
    "\n",
    "    # index set ids\n",
    "    if validation:\n",
    "        train_ids = id_list[:train_len]\n",
    "        val_ids = id_list[train_len:train_len+test_len]\n",
    "\n",
    "    else:\n",
    "        train_ids = id_list[:train_len+test_len]\n",
    "        val_ids = None\n",
    "\n",
    "    test_ids = id_list[train_len+test_len:]\n",
    "\n",
    "    print('total ids:', id_list_len)\n",
    "\n",
    "    print('train ids: {}, prop: {:.3f}'.format(\n",
    "        len(train_ids),\n",
    "        len(train_ids) / id_list_len\n",
    "    ))\n",
    "\n",
    "    if validation:\n",
    "        print('val ids: {}, prop: {:.3f}'.format(\n",
    "            len(val_ids),\n",
    "            len(val_ids) / id_list_len\n",
    "        ))\n",
    "\n",
    "    print('test ids: {}, prop: {:.3f}\\n'.format(\n",
    "        len(test_ids),\n",
    "        len(test_ids) / id_list_len\n",
    "    ))\n",
    "\n",
    "    return train_ids, val_ids, test_ids\n",
    "\n",
    "# function to index pos/neg dataframes by set patient ids and merge them\n",
    "def index_dataframes(df_obj_list, ids, id_var):\n",
    "    # zip pos/neg dataframes and ids\n",
    "    components = zip([df_obj.df for df_obj in df_obj_list], ids)\n",
    "\n",
    "    # index dataframes by ids for pos/neg\n",
    "    df_list = [df[df[id_var].isin(ids)] for df, ids in components]\n",
    "\n",
    "    # merge pos/neg dataframes\n",
    "    out_df = pd.concat(df_list, axis=0)\n",
    "    return out_df\n",
    "\n",
    "# function to split a positive and negative dataframe into train/val/test\n",
    "# then merge positive and negative for each\n",
    "def split_n_dataframes(df_list, id_var: str = 'tweet_id',\n",
    "                       test_prop: float = 0.2, seed: int = 13,\n",
    "                       validation: bool = True, label_col: str = 'label'):\n",
    "    # add label columns to dataframes\n",
    "    for df_obj in df_list:\n",
    "        df_obj.df.loc[:, 'class_label'] = df_obj.class_val\n",
    "\n",
    "    # get empty list to put dataframe set IDs\n",
    "    df_ids = []\n",
    "\n",
    "    # get ids for each split dataframe\n",
    "    for df_obj in df_list:\n",
    "        train_ids, val_ids, test_ids = split_ids(\n",
    "            df_obj.df[id_var],\n",
    "            test_prop,\n",
    "            validation,\n",
    "            seed\n",
    "        )\n",
    "        df_ids.append([train_ids, val_ids, test_ids])\n",
    "\n",
    "    # transpose list to get sublists of all train set IDs, val sets IDs, etc.\n",
    "    trans_df_ids = [i for i in zip(*df_ids)]\n",
    "\n",
    "    # prepare lists for indexing\n",
    "    train_ids = trans_df_ids[0]\n",
    "    val_ids = trans_df_ids[1]\n",
    "    test_ids = trans_df_ids[2]\n",
    "\n",
    "    # index split dataframes\n",
    "    train_df = index_dataframes(df_list, train_ids, id_var)\n",
    "    test_df = index_dataframes(df_list, test_ids, id_var)\n",
    "    if validation:\n",
    "        val_df = index_dataframes(df_list, val_ids, id_var)\n",
    "\n",
    "    # shuffle dataframes\n",
    "    train_df = train_df.sample(frac=1, random_state=seed).reset_index()\n",
    "    test_df = test_df.sample(frac=1, random_state=seed).reset_index()\n",
    "    if validation:\n",
    "        val_df = val_df.sample(frac=1, random_state=seed).reset_index()\n",
    "    else:\n",
    "        val_df = None\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2289c9-ae51-4aaf-9215-cc45afd62bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total ids: 534\n",
      "train ids: 320, prop: 0.599\n",
      "val ids: 106, prop: 0.199\n",
      "test ids: 108, prop: 0.202\n",
      "\n",
      "total ids: 2765\n",
      "train ids: 1659, prop: 0.600\n",
      "val ids: 553, prop: 0.200\n",
      "test ids: 553, prop: 0.200\n",
      "\n",
      "train size: 1979\n",
      "val size: 659\n",
      "test size: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1148482/1235383812.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_obj.df.loc[:, 'class_label'] = df_obj.class_val\n",
      "/tmp/ipykernel_1148482/1235383812.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_obj.df.loc[:, 'class_label'] = df_obj.class_val\n"
     ]
    }
   ],
   "source": [
    "# define constants\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION = True\n",
    "SEED = 13\n",
    "\n",
    "# split on label first\n",
    "pos_df = df[df['label'] == 1]\n",
    "neg_df = df[df['label'] == 0]\n",
    "\n",
    "df_list = [FrameParams(pos_df, 'pos', 1.0), FrameParams(neg_df, 'neg', 0.0)]\n",
    "\n",
    "# split each label df by username, then combine them into a single\n",
    "# dataframe for each split\n",
    "train_df, val_df, test_df = split_n_dataframes(\n",
    "    df_list,\n",
    "    test_prop=TEST_SIZE,\n",
    "    validation=VALIDATION,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print('train size:', len(train_df))\n",
    "print('val size:', len(val_df))\n",
    "print('test size:', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "055549ed-0647-438a-9000-43999f0b1beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train distribution:\n",
      "label\n",
      "0    0.838302\n",
      "1    0.161698\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "val distribution:\n",
      "label\n",
      "0    0.83915\n",
      "1    0.16085\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "test distribution:\n",
      "label\n",
      "0    0.836611\n",
      "1    0.163389\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'\\ntrain distribution:\\n{train_df.label.value_counts(dropna=False, normalize=True)}')\n",
    "print(f'\\nval distribution:\\n{val_df.label.value_counts(dropna=False, normalize=True)}')\n",
    "print(f'\\ntest distribution:\\n{test_df.label.value_counts(dropna=False, normalize=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81213ef5-0139-4200-85cd-542c00a5e234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train distribution:\n",
      "label\n",
      "0    1659\n",
      "1     320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "val distribution:\n",
      "label\n",
      "0    553\n",
      "1    106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "test distribution:\n",
      "label\n",
      "0    553\n",
      "1    108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'\\ntrain distribution:\\n{train_df.label.value_counts(dropna=False, normalize=False)}')\n",
    "print(f'\\nval distribution:\\n{val_df.label.value_counts(dropna=False, normalize=False)}')\n",
    "print(f'\\ntest distribution:\\n{test_df.label.value_counts(dropna=False, normalize=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e9689d4-3074-4347-ad46-6b0d50305e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load roberta base as a tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c86a04-2ec2-468e-81e4-3293c6b5244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    class is very closely based on the huggingface tutorial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_len, id_col: str = 'tweet_id',\n",
    "                 text_col: str = 'text', target_col: str = 'class_label'):\n",
    "        self.tokenizer = tokenizer\n",
    "        # self.data = dataframe\n",
    "        self.tweet_id_list = list(dataframe[id_col])\n",
    "        self.text_list = list(dataframe[text_col])\n",
    "        self.label_list = list(dataframe[target_col])\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # get length of dataset (required for dataloader)\n",
    "        return len(self.text_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # extract text\n",
    "        text = str(self.text_list[idx])\n",
    "\n",
    "        # extract label\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        # tokenize text\n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            # add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        # unpack encoded text\n",
    "        ids = encoded_text['input_ids']\n",
    "        attention_mask = encoded_text['attention_mask']\n",
    "        token_type_ids = encoded_text[\"token_type_ids\"]\n",
    "\n",
    "        # wrap outputs in dict\n",
    "        out_dict = {\n",
    "            'tweet_id_list': self.tweet_id_list,\n",
    "            'id_tensor': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask_tensor': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'token_type_tensor': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'label_tensor': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "        return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adcdfa05-e41c-4e5f-a5cb-b78655192edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "\n",
    "# load dataframes into dataset objects\n",
    "train_ds = TweetDataset(train_df, tokenizer, MAX_LEN)\n",
    "val_ds = TweetDataset(val_df, tokenizer, MAX_LEN)\n",
    "test_ds = TweetDataset(test_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01329235-c7db-4897-82d9-ee2cb6d32af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, batch_size, shuffle: bool = True,\n",
    "                   pin_memory: bool = True, num_workers: int = 0,\n",
    "                   prefetch_factor: int or None = None):\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=prefetch_factor\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# load datasets into loaders\n",
    "train_loader = get_dataloader(train_ds, BATCH_SIZE)\n",
    "val_loader = get_dataloader(val_ds, BATCH_SIZE)\n",
    "test_loader = get_dataloader(test_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60030d26-aac6-4971-8da7-6cfe59fa104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRoberta(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    model subclass to define the RoBERTa architecture, also closely based on\n",
    "    the huggingface tutorial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_percent, num_classes, pt_model_name: str = 'roberta-base'):\n",
    "        super().__init__()\n",
    "        self.base_model = RobertaModel.from_pretrained(pt_model_name)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(drop_percent)\n",
    "        self.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # get outputs from base model\n",
    "        base_outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # extract hidden state from roberta base outputs\n",
    "        hidden_state = base_outputs[0]\n",
    "        x = hidden_state[:, 0]\n",
    "\n",
    "        # define the linear layer preceding the classifier\n",
    "        # and apply ReLU activation to its outputs\n",
    "        x = self.pre_classifier(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "\n",
    "        # define the dropout layer and classifier\n",
    "        # and apply Sigmoid activation to its outputs\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        outputs = torch.nn.Sigmoid()(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc898de7-cd64-4f48-b3b0-7932f8ea5d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomRoberta(\n",
       "  (base_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model and send it to the gpu\n",
    "model = CustomRoberta(0.3, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd9c00e-b443-4640-b86b-c47df908b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader_dict, metric_collection, \n",
    "                criterion, optimizer, save_dir: str or None = None, \n",
    "                num_epochs: int = 25, monitor_metric: str = 'val_loss'):\n",
    "    if save_dir is not None:\n",
    "        # if save dir doesn't exist, make it\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        model_save_path = os.path.join(save_dir, 'best_model_params.pth')\n",
    "    \n",
    "    # save base weights\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # initialize the best metric based on what the monitor metric is\n",
    "    # (and if it should be maximized or minimized)\n",
    "    if monitor_metric.split('_')[-1] == 'loss':\n",
    "        best_metric = np.inf\n",
    "    else:\n",
    "        best_metric = -np.inf\n",
    "\n",
    "    # iterate over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch} {'-' * 40}\")\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            # running_size = 0\n",
    "\n",
    "            # select current data loader\n",
    "            phase_loader = loader_dict[phase]\n",
    "            phase_size = len(phase_loader)\n",
    "\n",
    "            # iterate over data in current phase loader\n",
    "            with tqdm(phase_loader, unit=\"batch\", total=phase_size) as epoch_iter:\n",
    "                for batch, data in enumerate(epoch_iter):\n",
    "                    # unpack data dict\n",
    "                    id_tensor = data['id_tensor'].to(device)\n",
    "                    mask_tensor = data['mask_tensor'].to(device)\n",
    "                    token_type_tensor = data['token_type_tensor'].to(device)\n",
    "                    label_tensor = data['label_tensor'].to(device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(\n",
    "                            id_tensor,\n",
    "                            mask_tensor,\n",
    "                            token_type_tensor\n",
    "                        )\n",
    "                        preds = torch.squeeze(outputs)\n",
    "                        loss = criterion(preds, label_tensor)\n",
    "\n",
    "                        # update running loss\n",
    "                        running_loss += loss.item() #* label_tensor.size(0)\n",
    "                        # running_size += label_tensor.size(0)\n",
    "\n",
    "                        # update metric collection\n",
    "                        metric_collection.update(preds, label_tensor)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # update metrics after each 10% chunk\n",
    "                    # or if in val update on last batch\n",
    "                    if ((phase == 'train') & (batch % (max(phase_size // 10, 1)) == 0)) |\\\n",
    "                    ((phase == 'val') & (batch == (phase_size - 1))):\n",
    "                        phase_metrics = metric_collection.compute()\n",
    "\n",
    "                        phase_metrics_dict = format_metrics_dict(\n",
    "                            loss, #/ running_size, \n",
    "                            phase_metrics, \n",
    "                            phase\n",
    "                        )\n",
    "                        epoch_iter.set_postfix(phase_metrics_dict)\n",
    "                        \n",
    "                    \n",
    "\n",
    "            # reset metric collection\n",
    "            metric_collection.reset()\n",
    "            \n",
    "            # save the model weights if the current val monitor metric is the best so far\n",
    "            if (save_dir is not None) & is_metric_better(monitor_metric, phase_metrics_dict, best_metric):\n",
    "                best_metric = phase_metrics_dict[monitor_metric]\n",
    "                \n",
    "                print(f\"saving model with best {monitor_metric} '{best_metric:.4f}'...\")\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # load best model weights and evaluate on test set\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    id_list, pred_list, label_list = evaluate_model(model, loader_dict['test'], metric_collection, criterion)\n",
    "    return id_list, pred_list, label_list\n",
    "\n",
    "def evaluate_model(model, test_loader, metric_collection, criterion):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    tweet_id_list = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "\n",
    "    phase_size = len(test_loader)\n",
    "\n",
    "    # iterate over data in current phase loader\n",
    "    with tqdm(test_loader, unit=\"batch\", total=phase_size) as epoch_iter:\n",
    "        for batch, data in enumerate(epoch_iter):\n",
    "            # unpack data dict\n",
    "            batch_id_list = data['tweet_id_list']\n",
    "            id_tensor = data['id_tensor'].to(device)\n",
    "            mask_tensor = data['mask_tensor'].to(device)\n",
    "            token_type_tensor = data['token_type_tensor'].to(device)\n",
    "            label_tensor = data['label_tensor'].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            # optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(\n",
    "                    id_tensor,\n",
    "                    mask_tensor,\n",
    "                    token_type_tensor\n",
    "                )\n",
    "                preds = torch.squeeze(outputs)\n",
    "                loss = criterion(preds, label_tensor)\n",
    "\n",
    "                # update running loss\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # update metric collection\n",
    "                metric_collection.update(preds, label_tensor)\n",
    "                \n",
    "                tweet_id_list += batch_id_list\n",
    "                pred_list.append(preds.detach().cpu()) #.numpy())\n",
    "                label_list.append(label_tensor.detach().cpu().numpy())\n",
    "\n",
    "    phase_metrics = metric_collection.compute()\n",
    "\n",
    "    phase_metrics_dict = format_metrics_dict(\n",
    "        loss,\n",
    "        phase_metrics, \n",
    "        'test'\n",
    "    )\n",
    "\n",
    "    # print metrics\n",
    "    for k, v in phase_metrics_dict.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "        \n",
    "    return tweet_id_list, pred_list, label_list\n",
    "\n",
    "def is_metric_better(monitor_metric, metrics_dict, best_eval):\n",
    "    \"\"\"\n",
    "    function to determine if the monitor metric should be maximized or minimized\n",
    "    \"\"\"\n",
    "    curr_eval = metrics_dict.get(monitor_metric)\n",
    "    if curr_eval is None:\n",
    "        return False\n",
    "    \n",
    "    if monitor_metric.split('_')[-1] == 'loss':\n",
    "        return curr_eval < best_eval\n",
    "    else:\n",
    "        return curr_eval > best_eval\n",
    "    \n",
    "def format_metrics_dict(loss, metrics_dict, set_name: str):\n",
    "    out_metrics_dict = {}\n",
    "    out_metrics_dict[f'{set_name}_loss'] = loss.item()\n",
    "\n",
    "    for k, v in metrics_dict.items():\n",
    "        out_metrics_dict[f'{set_name}_{k}'] = v.item()\n",
    "\n",
    "    return out_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86705147-d18a-4c7f-9c67-5382abecff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricCollection(\n",
       "  (acc): BinaryAccuracy()\n",
       "  (auc): BinaryAUROC()\n",
       "  (f1): BinaryF1Score()\n",
       "  (prec): BinaryPrecision()\n",
       "  (rec): BinaryRecall()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define metric collection\n",
    "TASK_TYPE = 'binary'\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "metric_collection = MetricCollection({\n",
    "    'acc': Accuracy(task=TASK_TYPE, num_classes=NUM_CLASSES),\n",
    "    'auc': AUROC(task=TASK_TYPE, num_classes=NUM_CLASSES),\n",
    "    'prec': Precision(task=TASK_TYPE, num_classes=NUM_CLASSES),\n",
    "    'rec': Recall(task=TASK_TYPE, num_classes=NUM_CLASSES),\n",
    "    'f1': F1Score(task=TASK_TYPE, num_classes=NUM_CLASSES)\n",
    "})\n",
    "\n",
    "metric_collection.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "751916f6-5cfc-4420-bee1-00853debcea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc600d79-edd9-4847-8dfe-df19bd24b348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:45<00:00,  2.86s/batch, train_loss=0.638, train_acc=0.424, train_auc=0.508, train_f1=0.305, train_prec=0.18, train_rec=1]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.32batch/s, val_loss=0.623, val_acc=0.839, val_auc=0.642, val_f1=0, val_prec=0, val_rec=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_f1 '0.0000'...\n",
      "\n",
      "Epoch 1 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.425, train_acc=0.838, train_auc=0.529, train_f1=0, train_prec=0, train_rec=0]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.513, val_acc=0.839, val_auc=0.69, val_f1=0, val_prec=0, val_rec=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.397, train_acc=0.838, train_auc=0.659, train_f1=0, train_prec=0, train_rec=0]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.443, val_acc=0.839, val_auc=0.891, val_f1=0, val_prec=0, val_rec=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.327, train_acc=0.838, train_auc=0.872, train_f1=0, train_prec=0, train_rec=0]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.361, val_acc=0.839, val_auc=0.948, val_f1=0, val_prec=0, val_rec=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.467, train_acc=0.851, train_auc=0.925, train_f1=0, train_prec=0, train_rec=0]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.236, val_acc=0.924, val_auc=0.955, val_f1=0.737, val_prec=0.833, val_rec=0.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_f1 '0.7368'...\n",
      "\n",
      "Epoch 5 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.142, train_acc=0.922, train_auc=0.923, train_f1=0.727, train_prec=0.889, train_rec=0.615]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.129, val_acc=0.918, val_auc=0.962, val_f1=0.761, val_prec=0.717, val_rec=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_f1 '0.7611'...\n",
      "\n",
      "Epoch 6 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.174, train_acc=0.934, train_auc=0.958, train_f1=0.737, train_prec=0.667, train_rec=0.824]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.34batch/s, val_loss=0.0383, val_acc=0.93, val_auc=0.964, val_f1=0.783, val_prec=0.783, val_rec=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_f1 '0.7830'...\n",
      "\n",
      "Epoch 7 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.113, train_acc=0.941, train_auc=0.969, train_f1=0.846, train_prec=0.815, train_rec=0.88]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.149, val_acc=0.936, val_auc=0.97, val_f1=0.802, val_prec=0.802, val_rec=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_f1 '0.8019'...\n",
      "\n",
      "Epoch 8 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.16, train_acc=0.951, train_auc=0.966, train_f1=0.789, train_prec=0.789, train_rec=0.789] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.486, val_acc=0.939, val_auc=0.971, val_f1=0.817, val_prec=0.795, val_rec=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_f1 '0.8165'...\n",
      "\n",
      "Epoch 9 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.0634, train_acc=0.959, train_auc=0.97, train_f1=0.765, train_prec=0.812, train_rec=0.722] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.359, val_acc=0.936, val_auc=0.971, val_f1=0.796, val_prec=0.82, val_rec=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0563, train_acc=0.962, train_auc=0.973, train_f1=0.85, train_prec=0.81, train_rec=0.895]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.34batch/s, val_loss=0.253, val_acc=0.938, val_auc=0.974, val_f1=0.806, val_prec=0.81, val_rec=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.143, train_acc=0.97, train_auc=0.976, train_f1=0.936, train_prec=0.917, train_rec=0.957]  \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.355, val_acc=0.933, val_auc=0.975, val_f1=0.8, val_prec=0.772, val_rec=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.104, train_acc=0.971, train_auc=0.98, train_f1=0.914, train_prec=1, train_rec=0.842]  \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.0429, val_acc=0.93, val_auc=0.973, val_f1=0.796, val_prec=0.75, val_rec=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.167, train_acc=0.969, train_auc=0.976, train_f1=0.895, train_prec=0.81, train_rec=1] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.0701, val_acc=0.942, val_auc=0.973, val_f1=0.814, val_prec=0.847, val_rec=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.11, train_acc=0.974, train_auc=0.985, train_f1=0.955, train_prec=1, train_rec=0.913]  \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.346, val_acc=0.929, val_auc=0.973, val_f1=0.789, val_prec=0.752, val_rec=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.0891, train_acc=0.979, train_auc=0.982, train_f1=0.95, train_prec=0.95, train_rec=0.95]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.409, val_acc=0.932, val_auc=0.972, val_f1=0.8, val_prec=0.756, val_rec=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0416, train_acc=0.981, train_auc=0.988, train_f1=0.9, train_prec=0.818, train_rec=1]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.2, val_acc=0.929, val_auc=0.971, val_f1=0.791, val_prec=0.748, val_rec=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.0427, train_acc=0.98, train_auc=0.986, train_f1=1, train_prec=1, train_rec=1] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.243, val_acc=0.93, val_auc=0.973, val_f1=0.795, val_prec=0.754, val_rec=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0438, train_acc=0.982, train_auc=0.987, train_f1=0.98, train_prec=1, train_rec=0.96]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.31batch/s, val_loss=0.383, val_acc=0.936, val_auc=0.972, val_f1=0.802, val_prec=0.802, val_rec=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0701, train_acc=0.98, train_auc=0.992, train_f1=0.978, train_prec=1, train_rec=0.957] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.166, val_acc=0.939, val_auc=0.971, val_f1=0.808, val_prec=0.824, val_rec=0.792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.103, train_acc=0.983, train_auc=0.99, train_f1=0.933, train_prec=0.933, train_rec=0.933]  \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.34batch/s, val_loss=0.183, val_acc=0.938, val_auc=0.971, val_f1=0.802, val_prec=0.822, val_rec=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0606, train_acc=0.983, train_auc=0.989, train_f1=0.944, train_prec=1, train_rec=0.895]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.0129, val_acc=0.941, val_auc=0.973, val_f1=0.815, val_prec=0.819, val_rec=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.068, train_acc=0.982, train_auc=0.99, train_f1=1, train_prec=1, train_rec=1]  \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.34batch/s, val_loss=0.438, val_acc=0.942, val_auc=0.972, val_f1=0.826, val_prec=0.804, val_rec=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_f1 '0.8257'...\n",
      "\n",
      "Epoch 23 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0181, train_acc=0.985, train_auc=0.994, train_f1=1, train_prec=1, train_rec=1]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.217, val_acc=0.942, val_auc=0.971, val_f1=0.822, val_prec=0.815, val_rec=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.146, train_acc=0.985, train_auc=0.99, train_f1=0.914, train_prec=0.941, train_rec=0.889]  \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.34batch/s, val_loss=0.156, val_acc=0.941, val_auc=0.971, val_f1=0.813, val_prec=0.825, val_rec=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0166, train_acc=0.986, train_auc=0.993, train_f1=1, train_prec=1, train_rec=1]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.34batch/s, val_loss=0.18, val_acc=0.938, val_auc=0.971, val_f1=0.814, val_prec=0.783, val_rec=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.119, train_acc=0.986, train_auc=0.992, train_f1=0.947, train_prec=0.947, train_rec=0.947] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.0742, val_acc=0.938, val_auc=0.971, val_f1=0.811, val_prec=0.793, val_rec=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.0824, train_acc=0.986, train_auc=0.994, train_f1=0.944, train_prec=0.944, train_rec=0.944]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.34batch/s, val_loss=0.281, val_acc=0.936, val_auc=0.972, val_f1=0.811, val_prec=0.776, val_rec=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/batch, train_loss=0.0292, train_acc=0.984, train_auc=0.994, train_f1=0.977, train_prec=1, train_rec=0.955]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.437, val_acc=0.927, val_auc=0.971, val_f1=0.789, val_prec=0.738, val_rec=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:36<00:00,  2.31s/batch, train_loss=0.103, train_acc=0.984, train_auc=0.995, train_f1=0.919, train_prec=0.85, train_rec=1] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, val_loss=0.0432, val_acc=0.932, val_auc=0.972, val_f1=0.796, val_prec=0.765, val_rec=0.83]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.21batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.2447\n",
      "test_acc: 0.9213\n",
      "test_auc: 0.9550\n",
      "test_f1: 0.7759\n",
      "test_prec: 0.7258\n",
      "test_rec: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader_dict = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "\n",
    "train_out_tuple = train_model(\n",
    "    model, \n",
    "    loader_dict, \n",
    "    metric_collection, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    save_dir=\"./model_test_f1_4\", \n",
    "    num_epochs=30, \n",
    "    monitor_metric='val_f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42de62-a344-430f-ba7a-17d4eaa64261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e9b168e-afa2-4420-9039-d8a5f2938f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3630\n",
      "test_acc: 0.9198\n",
      "test_auc: 0.9368\n",
      "test_f1: 0.7759\n",
      "test_prec: 0.7258\n",
      "test_rec: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/opt/localdata/Data/bea/nlp/bmi550/project/model_test_f1_2/best_model_params.pth\"))\n",
    "\n",
    "id_list, pred_list, label_list = evaluate_model(model, test_loader, metric_collection, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf758ea3-1462-4389-af63-27596b6bb1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad0e56-4384-454c-9d7f-9658bf7b8f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1cf397-356e-414b-9c11-1279b659df4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
